---
title: "Interpretability and Explainability in Machine Learning"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Load the concrete dataset
library(readxl)
concrete <- as.data.frame(read_excel("Concrete_Data.xls"))
DescVars <- names(concrete)
names(concrete) <- c(
  "Cement", "Slag", "FlyAsh", "Water", "Superplast",
  "CoarseAggr", "FineAggr", "Age", "Strength"
)
```

**Data processing: Creating training and test sets**\
Create a training sample choosing 700 data at random. The non-chosen data will be the test set.

```{r}
# Set a seed for reproducibility
set.seed(123456)

# Create indices for the training set
train_indices <- sort(sample(1:nrow(concrete), size = 700, replace = FALSE))

# Split the data into training and test sets
train_set <- concrete[train_indices, ]
test_set <- concrete[-train_indices, ]

# Check the dimensions of the splits
cat("Training set dimensions: ", dim(train_set), "\n")
cat("Test set dimensions: ", dim(test_set), "\n")
```

**1. Fit a Random Forest**

a.  Compute the *Variable Importance* by the reduction of the **impurity** at the splits defined by each variable.

```{r}
library(ranger)

model_rf_imp <- ranger(
  Strength ~ .,
  data = train_set,
  importance = "impurity"
)
print(model_rf_imp)
```

b.  Compute the *Variable Importance* by out-of-bag random permutations.

```{r}
model_rf_perm <- ranger(
  Strength ~ .,
  data = train_set,
  importance = "permutation"
)
print(model_rf_perm)
```

c.  Do a graphical representation of both *Variable Importance* measures.

```{r}
library(vip)
library(gridExtra)

rf_imp_vip <- vip(model_rf_imp, num_features = 8)
rf_perm_vip <- vip(model_rf_perm, num_features = 8)
grid.arrange(rf_imp_vip, rf_perm_vip,
  ncol = 2,
  top = "Left: Reduction in impurity. Right: Out-of-bag permutations"
)
```

d.  Compute the *Variable Importance* of each variable by Shapley Values.

```{r}
library(DALEX)

rf_shapley <- vip(
  model_rf_imp,
  method = "shap",
  pred_wrapper = yhat,
  num_features = 8,
  train = train_set,
  newdata = test_set[, -which(names(test_set) == "Strength")]
)

grid.arrange(rf_imp_vip, rf_perm_vip, rf_shapley,
  ncol = 2, nrow = 2,
  top = "Top left: Impurity. Top right: OOB permutations. Bottom: Shapley values"
)
```

**2. Fit a linear model and a gam model**

a.  Summarize, numerically and graphically, the fitted models.

```{r}
# Linear model fit
lm_concrete <- lm(Strength ~ ., data = train_set)

# Numerical summary of the fitted model
(summ_lm_concrete <- summary(lm_concrete))

# Graphical summary for the linear model
par(mfrow = c(2, 2))  # Arrange plots in a 2x2 grid
plot(lm_concrete)

```

```{r}
library(mgcv)

# Fit a Generalized Additive Model (GAM)
gam_concrete <- gam(Strength ~ s(Cement) + s(Slag) + s(FlyAsh) + 
                      s(Water) + s(Superplast) + s(CoarseAggr) + 
                      s(FineAggr) + s(Age), 
                    data = train_set)

# Numerical summary of the fitted model
(summ_gam_concrete <- summary(gam_concrete))

# Graphical summary for the GAM model
par(mfrow = c(3, 3))
plot(gam_concrete, residuals = TRUE, rug = TRUE, pages = 1)
```

b.  Compute the *Variable Importance* by Shapley values in the linear and gam fitted models. Compare your results with what you have learned before.

```{r}
# Compute Shapley values for the linear model
lm_concrete_shapley <- vip(
  lm_concrete, 
  method = "shap",
  pred_wrapper = predict.lm,  
  train = train_set,          
  newdata = test_set,        
  num_features = ncol(train_set) - 1,  
  exact = TRUE                
)

# Plot Shapley values for the linear model
plot(lm_concrete_shapley)

```

```{r}
# Compute Shapley values for the GAM
gam_concrete_shapley <- vip(
  gam_concrete, 
  method = "shap",
  pred_wrapper = predict.gam,  
  train = train_set,          
  newdata = test_set,          
  num_features = ncol(train_set) - 1,  
  exact = TRUE               
)

# Plot Shapley values for the GAM
plot(gam_concrete_shapley)

```

```{r}
# Combine all plots
grid.arrange(
  rf_imp_vip, 
  rf_shapley, 
  lm_concrete_shapley, 
  gam_concrete_shapley, 
  ncol = 2, nrow = 2,
  top = "1,1: RF Impurity. 1,2: Shapley RF. 2,1: Shapley LM. 2,2: Shapley GAM"
)

```

**3.Relevance by Ghost Variables**

Compute the relevance by ghost variables in the three fitted models.

```{r}
library(grid)
library(ggplot2)
source("relev.ghost.var.R")  
```

```{r}
# GAM model
Rel_Gh_Var_gam <- relev.ghost.var(
  model = gam_concrete,                   
  newdata = test_set[, -which(names(test_set) == "Strength")], 
  y.ts = test_set$Strength,               
  func.model.ghost.var = lm
)

par(mar = c(4, 4, 2, 1))
plot.relev.ghost.var(
  Rel_Gh_Var_gam,
  n1 = 500,    
  ncols.plot = 3 
)

# Combine ghost variable relevance with Shapley values
aux <- cbind(
  Rel_Gh_Var_gam$relev.ghost, 
  gam_concrete_shapley$data$Importance
)

# Scatter plot
plot(aux[, 1], aux[, 2], 
     col = 0, 
     xlab = "Relevance by Ghost Variables", 
     ylab = "Shapley Variable Importance",
     main = "GAM model")

# Add text labels for each variable
text(aux[, 1], aux[, 2], labels = row.names(aux))

```

```{r}
Rel_Gh_Var_lm <- relev.ghost.var(
  model = lm_concrete,
  newdata = test_set[, -which(names(test_set) == "Strength")], 
  y.ts = test_set$Strength,                                   
  func.model.ghost.var = lm                              
)

par(mar = c(4, 4, 2, 1))
plot.relev.ghost.var(
  Rel_Gh_Var_lm,
  n1 = 500,    
  ncols.plot = 3 
)

# Combine ghost variable relevance with Shapley values
aux <- cbind(
  Rel_Gh_Var_lm$relev.ghost, 
  lm_concrete_shapley$data$Importance
)

# Scatter plot
plot(aux[, 1], aux[, 2], 
     col = 0, 
     xlab = "Relevance by Ghost Variables", 
     ylab = "Shapley Variable Importance",
     main = "Linear model")

# Add text labels for each variable
text(aux[, 1], aux[, 2], labels = row.names(aux))

```

```{r}
model_rf_imp <- ranger(
  x          = train_set[, setdiff(names(train_set), "Strength")],
  y          = train_set$Strength,
  importance = "impurity"
)
```

```{r}
# I was having problems with the "relev.ghost.var" function when using the "ranger" package to fit the random forest. I have changed to the "randomForest" library and then it works. The model should be the same as the one fitted before since we set a seed and specify the same number of trees.

library(randomForest)

model_rf <- randomForest(
  Strength ~ .,   
  data = train_set,
  importance = TRUE, 
  ntree = 500     
)
print(model_rf)
```

```{r}
Rel_Gh_Var_rf <- relev.ghost.var(
  model = model_rf,
  newdata = test_set, 
  y.ts = test_set$Strength,                                   
  func.model.ghost.var = lm
)

par(mar = c(4, 4, 2, 1))
plot.relev.ghost.var(
  Rel_Gh_Var_rf,
  n1 = 500,    
  ncols.plot = 3 
)

# Combine ghost variable relevance with Shapley values
aux <- cbind(
  Rel_Gh_Var_rf$relev.ghost, 
  rf_shapley$data$Importance
)

# Scatter plot
plot(aux[, 1], aux[, 2], 
     col = 0, 
     xlab = "Relevance by Ghost Variables", 
     ylab = "Shapley Variable Importance",
     main = "Random forest model")

# Add text labels for each variable
text(aux[, 1], aux[, 2], labels = row.names(aux))
```

**4. Global Importance Measures and Plots using the library DALEX**

a. Compute Variable Importance by Random Permutations
b. Do the Partial Dependence Plot for each explanatory variable.
c. Do the Local (or Conditional) Dependence Plot for each explanatory variable.

```{r, message=FALSE, warning=FALSE}

# Train a Random Forest model using the training set
rf_model <- randomForest(Strength ~ ., data = train_set, importance = TRUE)

# Create an explainer for the model
explainer <- explain(
  model = rf_model,
  data = train_set[, -ncol(train_set)], # Explanatory variables
  y = train_set$Strength,              # Target variable
  label = "Random Forest"
)

# (a) Compute Variable Importance by Random Permutations
importance <- model_parts(explainer)
print(importance)
plot(importance)

# (b) Partial Dependence Plots for each explanatory variable
pdp <- model_profile(explainer)
print(pdp)
plot(pdp)

# (c) Local (Conditional) Dependence Plots
# Example: First observation in the test set
local_profile <- predict_profile(explainer, new_observation = test_set[1, -ncol(test_set)])
print(local_profile)
plot(local_profile)
```

